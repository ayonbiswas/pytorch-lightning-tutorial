{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"monai==0.5.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "import pytorch_lightning as pl\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os\n",
    "import monai\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "from losses import *\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "import numpy as np\n",
    "\n",
    "# from source.ray_utils import * # create_search_space, create_test_search_space\n",
    "\n",
    "# import source.transforms as transforms\n",
    "# import source.transforms.oral_cavity_transforms as transforms\n",
    "# import source.losses as losses\n",
    "# import deepgrow\n",
    "from monai.metrics.meandice import compute_meandice\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-436ada3061fb6a2b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-436ada3061fb6a2b\");\n",
       "          const url = new URL(\"/proxy/7991/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/ --port 7991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size =  256,\n",
    "        data_dir=PATH_DATASETS\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((32,32)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningVAE(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super(LightningVAE, self).__init__()\n",
    "\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        self.latent_dim = config[\"latent_dim\"]\n",
    "\n",
    "        self.model = monai.networks.nets.VarAutoEncoder(\n",
    "            dimensions=2,  \n",
    "            kernel_size=config[\"kernel_size\"],\n",
    "            in_shape=[1, 32,32],\n",
    "            out_channels=1,\n",
    "            channels=config[\"channel\"],\n",
    "            strides=config[\"stride\"],\n",
    "            latent_size=config[\"latent_dim\"],\n",
    "            norm=config[\"norm\"],\n",
    "            dropout=config[\"dropout_rate\"],\n",
    "            num_res_units=config[\"num_resnets\"],\n",
    "        )\n",
    " \n",
    "        self.vae_loss = KLLoss(alpha=config[\"alpha\"], beta=config[\"beta\"])\n",
    "        self.dice = Dice()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        # calculate loss, dice and avg_kl by doing a forward of model\n",
    "\n",
    "\n",
    "        return {\"loss\": loss, \"dice\": dice, \"avg_kl\": avg_kl}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # aggregate loss , dice and avg kl and loog them in tensorboard \n",
    "\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        # calculate loss, dice and avg_kl\n",
    "        \n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"dice\": dice,\n",
    "            \"avg_kl\": avg_kl,\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # aggregate loss , dice and avg kl and loog them in tensorboard \n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        # log sampled images\n",
    "        if(self.current_epoch%5 == 0):\n",
    "            sample_out = self.forward(self.sample_random_batch)\n",
    "            sample_out = sample_out[0].detach().cpu().numpy()\n",
    "            sample_in = self.sample_random_batch.cpu().numpy()\n",
    "            data = []\n",
    "            slice_index = sample_out.shape[2]//2\n",
    "            for i in range(1):\n",
    "                for j in range(sample_out.shape[0]):\n",
    "                    data.append(sample_out[j,i])\n",
    "                for j in range(sample_out.shape[0]):\n",
    "                    data.append(sample_in[j,i])\n",
    "            data_tensor = torch.from_numpy(np.array(data)).unsqueeze(1)\n",
    "            grid = torchvision.utils.make_grid(data_tensor,\n",
    "                                              normalize = True, \n",
    "                                             scale_each = True,\n",
    "                                             nrow = sample_out.shape[0])\n",
    "            self.logger.experiment.add_image(\"generated_images\", grid, self.current_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from ray.tune.integration.pytorch_lightning import (\n",
    "    TuneReportCallback,\n",
    "    TuneReportCheckpointCallback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single run\n",
    "def train_vae_single(config, num_epochs=1, num_gpus=1):\n",
    "    model = LightningVAE(config)\n",
    "    data_module = MNISTDataModule(\n",
    "        batch_size=config[\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_epochs,\n",
    "        gpus=num_gpus,\n",
    "        logger=TensorBoardLogger(save_dir=\"./logs\"),\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/opt/conda/envs/ray-lightning/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type           | Params\n",
      "--------------------------------------------\n",
      "0 | model    | VarAutoEncoder | 899 K \n",
      "1 | vae_loss | KLLoss         | 0     \n",
      "2 | dice     | Dice           | 0     \n",
      "--------------------------------------------\n",
      "899 K     Trainable params\n",
      "0         Non-trainable params\n",
      "899 K     Total params\n",
      "3.598     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ray-lightning/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/opt/conda/envs/ray-lightning/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 2/235 [00:00<00:23,  9.85it/s, loss=1.75, v_num=28]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ray-lightning/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/closure.py:36: LightningDeprecationWarning: One of the returned values {'dice', 'avg_kl'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  91%|█████████▏| 215/235 [00:13<00:01, 16.31it/s, loss=1.22, v_num=28]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 217/235 [00:13<00:01, 16.37it/s, loss=1.22, v_num=28]\n",
      "Validating:  10%|█         | 2/20 [00:00<00:00, 18.58it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 221/235 [00:13<00:00, 16.49it/s, loss=1.22, v_num=28]\n",
      "Epoch 0:  96%|█████████▌| 225/235 [00:13<00:00, 16.62it/s, loss=1.22, v_num=28]\n",
      "Epoch 0:  97%|█████████▋| 229/235 [00:13<00:00, 16.74it/s, loss=1.22, v_num=28]\n",
      "Validating:  70%|███████   | 14/20 [00:00<00:00, 27.50it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 235/235 [00:13<00:00, 16.90it/s, loss=1.22, v_num=28]\n",
      "Epoch 1:  30%|███       | 71/235 [00:04<00:10, 16.24it/s, loss=1.13, v_num=28] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ray-lightning/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        \"lr\": 0.00001,\n",
    "        \"latent_dim\": 256,\n",
    "        \"kernel_size\": 3,\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"alpha\": 1,\n",
    "        \"beta\": 0.01,\n",
    "        \"norm\": Norm.INSTANCE,\n",
    "         \"batch_size\": 256,\n",
    "        \n",
    "            \"val\": 3,\n",
    "            \"channel\": (32, 64, 64),\n",
    "            \"stride\": (1, 2, 4),\n",
    "            # \"resnet_units_batch\" : hp.choice(\"res6\", res_d6),\n",
    "\n",
    "        \"num_resnets\":  0,\n",
    "           \n",
    "        \n",
    "    }\n",
    "\n",
    "train_vae_single(param, num_epochs=20 , num_gpus =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-ray-lightning-py",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ray-lightning]",
   "language": "python",
   "name": "conda-env-ray-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
