{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "139b22c3",
   "metadata": {
    "id": "139b22c3",
    "outputId": "0da7bbd5-eab1-480f-9d09-277a55b0b4da",
    "papermill": {
     "duration": 1.37257,
     "end_time": "2022-04-10T02:25:47.997903",
     "exception": false,
     "start_time": "2022-04-10T02:25:46.625333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fe164bb",
   "metadata": {
    "id": "5fe164bb",
    "papermill": {
     "duration": 0.010794,
     "end_time": "2022-04-10T02:25:48.018602",
     "exception": false,
     "start_time": "2022-04-10T02:25:48.007808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92211adb",
   "metadata": {
    "id": "92211adb",
    "papermill": {
     "duration": 0.003162,
     "end_time": "2022-04-10T02:25:48.024919",
     "exception": false,
     "start_time": "2022-04-10T02:25:48.021757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "By using the `Trainer` you automatically get:\n",
    "1. Tensorboard logging\n",
    "2. Model checkpointing\n",
    "3. Training and validation loop\n",
    "4. early-stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9574d7",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "bd200cb848674c27a6ed8be04db5e92a",
      "e78bbfaafb00482b91f4eab0cddbdd2c",
      "4d981ca664bb427fbda7f999a4883276",
      "52a3cf8ba0894d47ba6d176eefd48bad",
      "194c70f182204bd0829e88a603d3c9c5"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-04-10T02:25:48.032399Z",
     "iopub.status.busy": "2022-04-10T02:25:48.032038Z",
     "iopub.status.idle": "2022-04-10T02:26:09.216202Z",
     "shell.execute_reply": "2022-04-10T02:26:09.215617Z"
    },
    "id": "9e9574d7",
    "outputId": "d7f441ea-c271-4834-d784-7b0283fe1524",
    "papermill": {
     "duration": 21.189592,
     "end_time": "2022-04-10T02:26:09.217669",
     "exception": false,
     "start_time": "2022-04-10T02:25:48.028077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /__w/1/s/.datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd200cb848674c27a6ed8be04db5e92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /__w/1/s/.datasets/MNIST/raw/train-images-idx3-ubyte.gz to /__w/1/s/.datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /__w/1/s/.datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78bbfaafb00482b91f4eab0cddbdd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /__w/1/s/.datasets/MNIST/raw/train-labels-idx1-ubyte.gz to /__w/1/s/.datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /__w/1/s/.datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d981ca664bb427fbda7f999a4883276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /__w/1/s/.datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to /__w/1/s/.datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /__w/1/s/.datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a3cf8ba0894d47ba6d176eefd48bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /__w/1/s/.datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to /__w/1/s/.datasets/MNIST/raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AzDevOps_azpcontainer/.local/lib/python3.9/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/home/AzDevOps_azpcontainer/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /__w/1/s/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | l1   | Linear | 7.9 K \n",
      "--------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n",
      "/home/AzDevOps_azpcontainer/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194c70f182204bd0829e88a603d3c9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Init our model\n",
    "mnist_model = MNISTModel()\n",
    "\n",
    "# Init DataLoader from MNIST Dataset\n",
    "train_ds = MNIST(PATH_DATASETS, train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=3,\n",
    "    progress_bar_refresh_rate=20,\n",
    ")\n",
    "\n",
    "# Train the model âš¡\n",
    "trainer.fit(mnist_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3ccda",
   "metadata": {
    "id": "6ec3ccda",
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.004913,
     "end_time": "2022-04-10T02:26:09.652877",
     "exception": false,
     "start_time": "2022-04-10T02:26:09.647964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MNIST Lightning Module Example\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Note what the following built-in functions are doing:\n",
    "\n",
    "1. [prepare_data()](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#prepare-data) ðŸ’¾\n",
    "    - This is where we can download the dataset. We point to our desired dataset and ask torchvision's `MNIST` dataset class to download if the dataset isn't found there.\n",
    "    - **Note we do not make any state assignments in this function** (i.e. `self.something = ...`)\n",
    "\n",
    "2. [setup(stage)](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#setup) âš™ï¸\n",
    "    - Loads in data from file and prepares PyTorch tensor datasets for each split (train, val, test).\n",
    "    - Setup expects a 'stage' arg which is used to separate logic for 'fit' and 'test'.\n",
    "    - If you don't mind loading all your datasets at once, you can set up a condition to allow for both 'fit' related setup and 'test' related setup to run whenever `None` is passed to `stage` (or ignore it altogether and exclude any conditionals).\n",
    "    - **Note this runs across all GPUs and it *is* safe to make state assignments here**\n",
    "\n",
    "3. [x_dataloader()](https://pytorch-lightning.readthedocs.io/en/stable/api_references.html#core-api) â™»ï¸\n",
    "    - `train_dataloader()`, `val_dataloader()`, and `test_dataloader()` all return PyTorch `DataLoader` instances that are created by wrapping their respective datasets that we prepared in `setup()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6d51b59-f489-4ef0-a214-aa65a4f084bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size =  256,\n",
    "        data_dir=PATH_DATASETS\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7381fde-1853-401f-a2ef-c94abaccf2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "736c59b1",
   "metadata": {
    "id": "736c59b1",
    "papermill": {
     "duration": 0.087198,
     "end_time": "2022-04-10T02:26:10.196565",
     "exception": false,
     "start_time": "2022-04-10T02:26:10.109367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, learning_rate=2e-4):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.num_classes = 10\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "\n",
    "        # Define PyTorch model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, self.num_classes),\n",
    "        )\n",
    "\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return {'loss' : loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        mean_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "\n",
    "        self.logger.experiment.add_scalar(\n",
    "            \"Training/loss\", mean_loss, self.current_epoch\n",
    "        )\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        # self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        # self.log(\"val_acc\", self.accuracy, prog_bar=True)\n",
    "        return {'loss' : loss, 'accuracy' : acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        mean_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        mean_acc = torch.stack([x[\"accuracy\"] for x in outputs]).mean()\n",
    "        \n",
    "\n",
    "        self.logger.experiment.add_scalar(\n",
    "            \"Validation/loss\", mean_loss, self.current_epoch\n",
    "        )\n",
    "        self.logger.experiment.add_scalar(\n",
    "            \"Validation/accuracy\", mean_acc, self.current_epoch\n",
    "        )\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        mean_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        mean_acc = torch.stack([x[\"accuracy\"] for x in outputs]).mean()\n",
    "        # print(mean_acc, mean_loss)\n",
    "        self.log(\"val_loss\", mean_loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", mean_acc, prog_bar=True)\n",
    "        # return {'loss' : mean_loss, 'accuracy' : mean_acc}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20ca7128",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d2c1cbb3130e4246b157582b25c0ec52",
      "b667094405d84527aa8cc17923a766de",
      "bff8dea71a504afd99c60da811ebb8fe",
      "c33a68b8444f47b596801f02c82f54b0",
      "6978fe74a7d44795836feb2fcdba92e5"
     ]
    },
    "id": "20ca7128",
    "outputId": "fd7b91a4-2380-4f4a-935e-8069a68f7845",
    "papermill": {
     "duration": 33.422451,
     "end_time": "2022-04-10T02:26:43.973982",
     "exception": false,
     "start_time": "2022-04-10T02:26:10.551531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | model    | Sequential | 55.1 K\n",
      "1 | accuracy | Accuracy   | 0     \n",
      "----------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 220/235 [00:07<00:00, 29.02it/s, loss=0.746, v_num=9]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [00:08<00:00, 28.50it/s, loss=0.693, v_num=9]\n",
      "Epoch 1:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 220/235 [00:07<00:00, 28.48it/s, loss=0.496, v_num=9]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [00:08<00:00, 27.90it/s, loss=0.474, v_num=9]\n",
      "Epoch 2:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 220/235 [00:07<00:00, 29.29it/s, loss=0.426, v_num=9]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [00:08<00:00, 28.82it/s, loss=0.404, v_num=9]\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [00:08<00:00, 28.78it/s, loss=0.404, v_num=9]\n"
     ]
    }
   ],
   "source": [
    "model = MNISTClassifier()\n",
    "data_module = MNISTDataModule()\n",
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=3,\n",
    "    progress_bar_refresh_rate=20,\n",
    ")\n",
    "trainer.fit(model,data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29dcb53",
   "metadata": {
    "id": "c29dcb53",
    "papermill": {
     "duration": 0.005205,
     "end_time": "2022-04-10T02:26:43.984907",
     "exception": false,
     "start_time": "2022-04-10T02:26:43.979702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Testing\n",
    "\n",
    "To test a model, call `trainer.test(model)`.\n",
    "\n",
    "Or, if you've just trained a model, you can just call `trainer.test()` and Lightning will automatically\n",
    "test using the best saved checkpoint (conditioned on val_loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25fd3ef0",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d1699fdd99454d9a842f1fc0d4d3eddf"
     ]
    },
    "id": "25fd3ef0",
    "outputId": "d7254b7b-aaef-4ad9-961f-abbe7bb27efd",
    "papermill": {
     "duration": 1.938945,
     "end_time": "2022-04-10T02:26:45.929007",
     "exception": false,
     "start_time": "2022-04-10T02:26:43.990062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 30.74it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'val_acc': 0.9122070670127869, 'val_loss': 0.31087276339530945}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 30.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.31087276339530945, 'val_acc': 0.9122070670127869}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model,data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adc78f",
   "metadata": {
    "id": "34adc78f",
    "papermill": {
     "duration": 0.005946,
     "end_time": "2022-04-10T02:26:46.150348",
     "exception": false,
     "start_time": "2022-04-10T02:26:46.144402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In Colab, you can use the TensorBoard magic function to view the logs that Lightning has created for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8504f4ed",
   "metadata": {
    "id": "8504f4ed",
    "outputId": "d9a6bbea-dcca-412b-edb7-fe3a0d7b7b12",
    "papermill": {
     "duration": 1.571464,
     "end_time": "2022-04-10T02:26:47.727718",
     "exception": false,
     "start_time": "2022-04-10T02:26:46.156254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 1997 (pid 11662), started 0:07:17 ago. (Use '!kill 11662' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d0ebce78a16f3b37\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d0ebce78a16f3b37\");\n",
       "          const url = new URL(\"/proxy/1997/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --host \"0.0.0.0\" --port 1997 --logdir lightning_logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa4cfb-bdc3-4eaf-892a-42d337fb27c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "mnist-hello-world.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-env-ray-lightning-py",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "jupytext": {
   "cell_metadata_filter": "colab,colab_type,id,-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ray-lightning]",
   "language": "python",
   "name": "conda-env-ray-lightning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 109.152823,
   "end_time": "2022-04-10T02:26:50.566146",
   "environment_variables": {},
   "exception": null,
   "input_path": "lightning_examples/mnist-hello-world/hello-world.ipynb",
   "output_path": ".notebooks/lightning_examples/mnist-hello-world.ipynb",
   "parameters": {},
   "start_time": "2022-04-10T02:25:01.413323",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
